\section{Related Work}
\label{sec:related_work}
%----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
There are few studies comparing the quality of manual and automated test suites. In one study researchers found that using automated test generation tools did not improve the ability to test the software~\cite{Fraser:2013:AWT:2483760.2483774}. However, the study does not measure the quality of manual and automated generated test suites directly. Furthermore, only Evosuite is used to evaluate the mutations and generate the tests. This paper expands upon the question of the usefulness of automated generated test suites, and if certain systems in generating test suites work better than others.

Another paper compares measuring quality between faults detection and mutation scores~\cite{JJI+14}. The research statistically proves that mutation score can be used as a test of quality of test suites in place of fault detections. The paper uses automated test suites to validate this research, and unlike this paper's research, the author's do not compare mutation score, branch coverage, and cyclomatic complexity as joint measurements of quality. 

There is research comparing multiple mutation analysis tools~\cite{ComparingAutomatedMutationTools:2013}. This paper differs from this research in specifically comparing mutation analysis tools for Java. MAJOR was recommended as one one of the premier tools, and was thus used for the evaluation.
